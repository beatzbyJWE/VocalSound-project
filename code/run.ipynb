{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93b71629-86e7-4696-937d-46a9dc8f48e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "import torch\n",
    "import shutil\n",
    "sys.path.append('/home/jake/repositories/vocalsound/src')\n",
    "import dataloaders\n",
    "import models\n",
    "from traintest import train, validate\n",
    "import ast\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df106a11-30c3-4c41-b72d-d6694ed88670",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "242fbb34-da59-4815-a60b-10f31d7cb408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am process 4220, running on jake-workstation: starting (Sat Jul 16 17:44:44 2022)\n"
     ]
    }
   ],
   "source": [
    "print(\"I am process %s, running on %s: starting (%s)\" % (\n",
    "        os.getpid(), os.uname()[1], time.asctime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea415fde-f955-424c-908e-cb01d958bd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from utilities import *\n",
    "from torch.optim.swa_utils import AveragedModel, SWALR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f88175f9-07df-4c6c-ac80-46eed45158b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(audio_model, train_loader, test_loader,\n",
    "          exp_dir,lr,weight_decay,n_epochs,n_print_steps,save_model): #exp_dir,lr,weight_decay,n_epochs,n_print_steps,save_model\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    torch.set_grad_enabled(True)\n",
    "    # Initialize all of the statistics we want to keep track of\n",
    "    batch_time = AverageMeter()\n",
    "    per_sample_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    per_sample_data_time = AverageMeter()\n",
    "    loss_meter = AverageMeter()\n",
    "    per_sample_dnn_time = AverageMeter()\n",
    "    progress = []\n",
    "    best_epoch, best_cum_epoch, best_mAP, best_acc, best_cum_mAP = 0, 0, -np.inf, -np.inf, -np.inf\n",
    "    global_step, epoch = 0, 0\n",
    "    swa_sign = False\n",
    "    start_time = time.time()\n",
    "    exp_dir = exp_dir\n",
    "\n",
    "    def _save_progress():\n",
    "        progress.append([epoch, global_step, best_epoch, best_mAP,\n",
    "                time.time() - start_time])\n",
    "        with open(\"%s/progress.pkl\" % exp_dir, \"wb\") as f:\n",
    "            pickle.dump(progress, f)\n",
    "\n",
    "    if not isinstance(audio_model, nn.DataParallel):\n",
    "        audio_model = nn.DataParallel(audio_model)\n",
    "\n",
    "    audio_model = audio_model.to(device)\n",
    "    # Set up the optimizer\n",
    "    audio_trainables = [p for p in audio_model.parameters() if p.requires_grad]\n",
    "    print('Total parameter number is : {:.3f} million'.format(sum(p.numel() for p in audio_model.parameters()) / 1000000))\n",
    "    print('Total trainable parameter number is : {:.3f} million'.format(sum(p.numel() for p in audio_trainables) / 1000000))\n",
    "    trainables = audio_trainables\n",
    "\n",
    "    optimizer = torch.optim.Adam(trainables, lr, weight_decay=weight_decay, betas=(0.95, 0.999))\n",
    "\n",
    "    print('now use new scheduler')\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, list(range(10, 60)), gamma=1.0)\n",
    "\n",
    "    epoch += 1\n",
    "\n",
    "    print(\"current #steps=%s, #epochs=%s\" % (global_step, epoch))\n",
    "    print(\"start training...\")\n",
    "\n",
    "    result = np.zeros([n_epochs, 10])\n",
    "    audio_model.train()\n",
    "    while epoch < n_epochs + 1:\n",
    "        begin_time = time.time()\n",
    "        end_time = time.time()\n",
    "        audio_model.train()\n",
    "        print(datetime.datetime.now())\n",
    "\n",
    "        for i, (audio_input, labels) in enumerate(train_loader):\n",
    "            # measure data loading time\n",
    "            B = audio_input.size(0)\n",
    "            audio_input = audio_input.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "            data_time.update(time.time() - end_time)\n",
    "            per_sample_data_time.update((time.time() - end_time) / audio_input.shape[0])\n",
    "            dnn_start_time = time.time()\n",
    "\n",
    "            audio_output = audio_model(audio_input)\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            loss = loss_fn(audio_output, torch.argmax(labels.long(), axis=1))\n",
    "\n",
    "            # original optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # record loss\n",
    "            loss_meter.update(loss.item(), B)\n",
    "            batch_time.update(time.time() - end_time)\n",
    "            per_sample_time.update((time.time() - end_time)/audio_input.shape[0])\n",
    "            per_sample_dnn_time.update((time.time() - dnn_start_time)/audio_input.shape[0])\n",
    "\n",
    "            print_step = global_step % n_print_steps == 0\n",
    "            early_print_step = epoch == 0 and global_step % (n_print_steps/10) == 0\n",
    "            print_step = print_step or early_print_step\n",
    "\n",
    "            if print_step and global_step != 0:\n",
    "                print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Per Sample Total Time {per_sample_time.avg:.5f}\\t'\n",
    "                  'Per Sample Data Time {per_sample_data_time.avg:.5f}\\t'\n",
    "                  'Per Sample DNN Time {per_sample_dnn_time.avg:.5f}\\t'\n",
    "                  'Train Loss {loss_meter.val:.4f}\\t'.format(\n",
    "                   epoch, i, len(train_loader), per_sample_time=per_sample_time, per_sample_data_time=per_sample_data_time,\n",
    "                      per_sample_dnn_time=per_sample_dnn_time, loss_meter=loss_meter), flush=True)\n",
    "                if np.isnan(loss_meter.avg):\n",
    "                    print(\"training diverged...\")\n",
    "                    return\n",
    "\n",
    "            end_time = time.time()\n",
    "            global_step += 1\n",
    "\n",
    "        print('start validation')\n",
    "        stats, valid_loss = validate(audio_model, test_loader, exp_dir, epoch)\n",
    "        print('validation finished')\n",
    "\n",
    "        cum_stats = stats\n",
    "\n",
    "        cum_mAP = np.mean([stat['AP'] for stat in cum_stats])\n",
    "        cum_mAUC = np.mean([stat['auc'] for stat in cum_stats])\n",
    "        cum_acc = np.mean([stat['acc'] for stat in cum_stats])\n",
    "\n",
    "        mAP = np.mean([stat['AP'] for stat in stats])\n",
    "        mAUC = np.mean([stat['auc'] for stat in stats])\n",
    "        acc = np.mean([stat['acc'] for stat in stats])\n",
    "\n",
    "        middle_ps = [stat['precisions'][int(len(stat['precisions'])/2)] for stat in stats]\n",
    "        middle_rs = [stat['recalls'][int(len(stat['recalls'])/2)] for stat in stats]\n",
    "        average_precision = np.mean(middle_ps)\n",
    "        average_recall = np.mean(middle_rs)\n",
    "\n",
    "        print(\"---------------------Epoch {:d} Results---------------------\".format(epoch))\n",
    "        print(\"ACC: {:.6f}\".format(acc))\n",
    "        print(\"mAP: {:.6f}\".format(mAP))\n",
    "        print(\"AUC: {:.6f}\".format(mAUC))\n",
    "        print(\"Avg Precision: {:.6f}\".format(average_precision))\n",
    "        print(\"Avg Recall: {:.6f}\".format(average_recall))\n",
    "        print(\"d_prime: {:.6f}\".format(d_prime(mAUC)))\n",
    "        print(\"train_loss: {:.6f}\".format(loss_meter.avg))\n",
    "        print(\"valid_loss: {:.6f}\".format(valid_loss))\n",
    "\n",
    "        result[epoch-1, :] = [mAP, acc, average_precision, average_recall, d_prime(mAUC), loss_meter.avg, valid_loss, cum_mAP, cum_acc, optimizer.param_groups[0]['lr']]\n",
    "\n",
    "        np.savetxt(exp_dir + '/result.csv', result, delimiter=',')\n",
    "\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_acc_epoch = epoch\n",
    "            torch.save(audio_model.state_dict(), \"%s/models/best_audio_model.pth\" % (exp_dir))\n",
    "\n",
    "        if cum_mAP > best_cum_mAP:\n",
    "            best_cum_epoch = epoch\n",
    "            best_cum_mAP = cum_mAP\n",
    "\n",
    "        if save_model == True:\n",
    "            torch.save(audio_model.state_dict(), \"%s/models/audio_model.%d.pth\" % (exp_dir, epoch))\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        #print('number of params groups:' + str(len(optimizer.param_groups)))\n",
    "        print('Epoch-{0} lr: {1}'.format(epoch, optimizer.param_groups[0]['lr']))\n",
    "\n",
    "        with open(exp_dir + '/stats_' + str(epoch) +'.pickle', 'wb') as handle:\n",
    "            pickle.dump(stats, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        _save_progress()\n",
    "\n",
    "        finish_time = time.time()\n",
    "        print('epoch {:d} training time: {:.3f}'.format(epoch, finish_time-begin_time))\n",
    "\n",
    "        epoch += 1\n",
    "\n",
    "        batch_time.reset()\n",
    "        per_sample_time.reset()\n",
    "        data_time.reset()\n",
    "        per_sample_data_time.reset()\n",
    "        loss_meter.reset()\n",
    "        per_sample_dnn_time.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a7229a7-5b25-4c38-9097-ba63628cdff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(audio_model, val_loader, exp_dir, epoch):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    batch_time = AverageMeter()\n",
    "    if not isinstance(audio_model, nn.DataParallel):\n",
    "        audio_model = nn.DataParallel(audio_model)\n",
    "    audio_model = audio_model.to(device)\n",
    "    audio_model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    A_predictions = []\n",
    "    A_targets = []\n",
    "    A_loss = []\n",
    "    with torch.no_grad():\n",
    "        for i, (audio_input, labels) in enumerate(val_loader):\n",
    "            audio_input = audio_input.to(device)\n",
    "\n",
    "            # compute output\n",
    "            audio_output = audio_model(audio_input)\n",
    "            predictions = audio_output.to('cpu').detach()\n",
    "\n",
    "            A_predictions.append(predictions)\n",
    "            A_targets.append(labels)\n",
    "\n",
    "            # compute the loss\n",
    "            labels = labels.to(device)\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            # loss without reduction, easy to check per-sample loss\n",
    "            loss = loss_fn(audio_output, torch.argmax(labels.long(), axis=1))\n",
    "            A_loss.append(loss.to('cpu').detach())\n",
    "\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "        audio_output = torch.cat(A_predictions)\n",
    "        target = torch.cat(A_targets)\n",
    "        loss = np.mean(A_loss)\n",
    "        stats = calculate_stats(audio_output, target)\n",
    "\n",
    "        # save the prediction here\n",
    "        exp_dir = exp_dir\n",
    "        if os.path.exists(exp_dir+'/predictions') == False:\n",
    "            os.mkdir(exp_dir+'/predictions')\n",
    "            np.savetxt(exp_dir+'/predictions/target.csv', target, delimiter=',')\n",
    "        np.savetxt(exp_dir+'/predictions/predictions_' + str(epoch) + '.csv', audio_output, delimiter=',')\n",
    "\n",
    "    return stats, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fd3d053-0d28-411e-a7c2-9c50d58bce19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model='eff_mean'\n",
    "model_size=0\n",
    "imagenet_pretrain=False\n",
    "\n",
    "lr=1e-4\n",
    "freqm=48\n",
    "timem=192\n",
    "mixup=0\n",
    "batch_size=64\n",
    "\n",
    "data_dir='/home/jake/repositories/VocalSound-project/data'\n",
    "exp_dir=f'/home/jake/repositories/VocalSound-project/exp/vocalsound-{model}-{lr}'\n",
    "\n",
    "CUDA_CACHE_DISABLE=1\n",
    "n_class=6\n",
    "n_epochs=30\n",
    "weight_decay=5e-7\n",
    "data_train=f'{data_dir}/datafiles/tr.json'\n",
    "data_val=f'{data_dir}/datafiles/val.json'\n",
    "label_csv=f'{data_dir}/class_labels_indices_vs.csv'\n",
    "save_model=True\n",
    "n_print_steps=100\n",
    "num_workers=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6d7a776-12ff-4a87-9016-324dbd73dc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_conf = {'num_mel_bins': 128, 'target_length': 512, 'freqm': freqm, 'timem': timem, 'mixup': mixup, 'mode': 'train'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88052fe1-9955-481f-b4dc-290e7f4be200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced sampler is not used\n"
     ]
    }
   ],
   "source": [
    "print('balanced sampler is not used')\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataloaders.VSDataset(data_train, label_csv=label_csv, audio_conf=audio_conf, raw_wav_mode=False, specaug=True),\n",
    "    batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77353a72-ec03-4da6-bfb7-f892001e53e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_audio_conf = {'num_mel_bins': 128, 'target_length': 512, 'mixup': 0, 'mode': 'test'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8820b9b8-232a-4818-a738-772e200b9951",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataloaders.VSDataset(data_val, label_csv=label_csv, audio_conf=val_audio_conf, raw_wav_mode=False),\n",
    "    batch_size=200, shuffle=False, num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3f404c6-84e6-4d45-9044-b1a92d6e36f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not using imagenet pretrained network\n"
     ]
    }
   ],
   "source": [
    "if model == 'eff_mean':\n",
    "    audio_model = models.EffNetMean(label_dim=n_class, level=model_size, pretrain=imagenet_pretrain)\n",
    "else:\n",
    "    raise ValueError('Model Unrecognized')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52f8e08d-1867-42ad-b848-c111539ea1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting existing experiment directory /home/jake/repositories/VocalSound-project/exp/vocalsound-eff_mean-0.0001\n",
      "\n",
      "Creating experiment directory: /home/jake/repositories/VocalSound-project/exp/vocalsound-eff_mean-0.0001\n"
     ]
    }
   ],
   "source": [
    "# start training\n",
    "if os.path.exists(exp_dir):\n",
    "    print(f\"Deleting existing experiment directory {exp_dir}\")\n",
    "    shutil.rmtree(exp_dir)\n",
    "print(f\"\\nCreating experiment directory: {exp_dir}\")\n",
    "os.makedirs(f\"{exp_dir}/models\")\n",
    "#with open(\"%s/args.pkl\" % exp_dir, \"wb\") as f:\n",
    "#    pickle.dump(args, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "492dd730-5b3d-4354-955c-025e4dcdd1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now starting training for 30 epochs\n",
      "cuda\n",
      "Total parameter number is : 4.015 million\n",
      "Total trainable parameter number is : 4.015 million\n",
      "now use new scheduler\n",
      "current #steps=0, #epochs=1\n",
      "start training...\n",
      "2022-07-16 17:44:45.169260\n",
      "Epoch: [1][100/243]\tPer Sample Total Time 0.00278\tPer Sample Data Time 0.00008\tPer Sample DNN Time 0.00269\tTrain Loss 1.6997\t\n",
      "Epoch: [1][200/243]\tPer Sample Total Time 0.00262\tPer Sample Data Time 0.00004\tPer Sample DNN Time 0.00258\tTrain Loss 1.6541\t\n",
      "start validation\n",
      "validation finished\n",
      "---------------------Epoch 1 Results---------------------\n",
      "ACC: 0.167116\n",
      "mAP: 0.196946\n",
      "AUC: 0.552512\n",
      "Avg Precision: 0.184412\n",
      "Avg Recall: 0.542327\n",
      "d_prime: 0.186691\n",
      "train_loss: 1.738725\n",
      "valid_loss: 1.796750\n",
      "Epoch-1 lr: 0.0001\n",
      "epoch 1 training time: 43.053\n",
      "2022-07-16 17:45:28.222703\n",
      "Epoch: [2][57/243]\tPer Sample Total Time 0.00261\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.00248\tTrain Loss 1.6913\t\n",
      "Epoch: [2][157/243]\tPer Sample Total Time 0.00251\tPer Sample Data Time 0.00005\tPer Sample DNN Time 0.00246\tTrain Loss 1.5537\t\n",
      "start validation\n",
      "validation finished\n",
      "---------------------Epoch 2 Results---------------------\n",
      "ACC: 0.170350\n",
      "mAP: 0.222532\n",
      "AUC: 0.572025\n",
      "Avg Precision: 0.190090\n",
      "Avg Recall: 0.570274\n",
      "d_prime: 0.256724\n",
      "train_loss: 1.589218\n",
      "valid_loss: 1.855358\n",
      "Epoch-2 lr: 0.0001\n",
      "epoch 2 training time: 41.053\n",
      "2022-07-16 17:46:09.275418\n",
      "Epoch: [3][14/243]\tPer Sample Total Time 0.00299\tPer Sample Data Time 0.00051\tPer Sample DNN Time 0.00249\tTrain Loss 1.5360\t\n",
      "Epoch: [3][114/243]\tPer Sample Total Time 0.00252\tPer Sample Data Time 0.00007\tPer Sample DNN Time 0.00245\tTrain Loss 1.4925\t\n",
      "Epoch: [3][214/243]\tPer Sample Total Time 0.00249\tPer Sample Data Time 0.00004\tPer Sample DNN Time 0.00245\tTrain Loss 1.4124\t\n",
      "start validation\n",
      "validation finished\n",
      "---------------------Epoch 3 Results---------------------\n",
      "ACC: 0.700270\n",
      "mAP: 0.738714\n",
      "AUC: 0.918107\n",
      "Avg Precision: 0.309904\n",
      "Avg Recall: 0.954121\n",
      "d_prime: 1.969219\n",
      "train_loss: 1.470617\n",
      "valid_loss: 1.319880\n",
      "Epoch-3 lr: 0.0001\n",
      "epoch 3 training time: 41.015\n",
      "2022-07-16 17:46:50.290360\n",
      "Epoch: [4][71/243]\tPer Sample Total Time 0.00256\tPer Sample Data Time 0.00010\tPer Sample DNN Time 0.00246\tTrain Loss 1.4157\t\n",
      "Epoch: [4][171/243]\tPer Sample Total Time 0.00249\tPer Sample Data Time 0.00004\tPer Sample DNN Time 0.00245\tTrain Loss 1.3750\t\n",
      "start validation\n",
      "validation finished\n",
      "---------------------Epoch 4 Results---------------------\n",
      "ACC: 0.705660\n",
      "mAP: 0.775040\n",
      "AUC: 0.926088\n",
      "Avg Precision: 0.300031\n",
      "Avg Recall: 0.954153\n",
      "d_prime: 2.046735\n",
      "train_loss: 1.394994\n",
      "valid_loss: 1.304244\n",
      "Epoch-4 lr: 0.0001\n",
      "epoch 4 training time: 41.074\n",
      "2022-07-16 17:47:31.364748\n",
      "Epoch: [5][28/243]\tPer Sample Total Time 0.00272\tPer Sample Data Time 0.00025\tPer Sample DNN Time 0.00247\tTrain Loss 1.3193\t\n",
      "Epoch: [5][128/243]\tPer Sample Total Time 0.00251\tPer Sample Data Time 0.00006\tPer Sample DNN Time 0.00245\tTrain Loss 1.3391\t\n",
      "Epoch: [5][228/243]\tPer Sample Total Time 0.00248\tPer Sample Data Time 0.00003\tPer Sample DNN Time 0.00245\tTrain Loss 1.3384\t\n",
      "start validation\n",
      "validation finished\n",
      "---------------------Epoch 5 Results---------------------\n",
      "ACC: 0.761725\n",
      "mAP: 0.842779\n",
      "AUC: 0.949674\n",
      "Avg Precision: 0.299229\n",
      "Avg Recall: 0.974660\n",
      "d_prime: 2.321718\n",
      "train_loss: 1.345441\n",
      "valid_loss: 1.255582\n",
      "Epoch-5 lr: 0.0001\n",
      "epoch 5 training time: 41.087\n",
      "2022-07-16 17:48:12.451728\n",
      "Epoch: [6][85/243]\tPer Sample Total Time 0.00254\tPer Sample Data Time 0.00008\tPer Sample DNN Time 0.00246\tTrain Loss 1.3494\t\n",
      "Epoch: [6][185/243]\tPer Sample Total Time 0.00249\tPer Sample Data Time 0.00004\tPer Sample DNN Time 0.00245\tTrain Loss 1.4090\t\n",
      "start validation\n",
      "validation finished\n",
      "---------------------Epoch 6 Results---------------------\n",
      "ACC: 0.791914\n",
      "mAP: 0.875822\n",
      "AUC: 0.956150\n",
      "Avg Precision: 0.296979\n",
      "Avg Recall: 0.977884\n",
      "d_prime: 2.414999\n",
      "train_loss: 1.316149\n",
      "valid_loss: 1.227693\n",
      "Epoch-6 lr: 0.0001\n",
      "epoch 6 training time: 41.021\n",
      "2022-07-16 17:48:53.472312\n",
      "Epoch: [7][42/243]\tPer Sample Total Time 0.00262\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.00247\tTrain Loss 1.2754\t\n",
      "Epoch: [7][142/243]\tPer Sample Total Time 0.00250\tPer Sample Data Time 0.00005\tPer Sample DNN Time 0.00246\tTrain Loss 1.3707\t\n",
      "Epoch: [7][242/243]\tPer Sample Total Time 0.00248\tPer Sample Data Time 0.00003\tPer Sample DNN Time 0.00245\tTrain Loss 1.3424\t\n",
      "start validation\n",
      "validation finished\n",
      "---------------------Epoch 7 Results---------------------\n",
      "ACC: 0.841509\n",
      "mAP: 0.905841\n",
      "AUC: 0.969882\n",
      "Avg Precision: 0.299624\n",
      "Avg Recall: 0.987603\n",
      "d_prime: 2.657395\n",
      "train_loss: 1.300338\n",
      "valid_loss: 1.192220\n",
      "Epoch-7 lr: 0.0001\n",
      "epoch 7 training time: 40.967\n",
      "2022-07-16 17:49:34.438886\n",
      "Epoch: [8][99/243]\tPer Sample Total Time 0.00253\tPer Sample Data Time 0.00007\tPer Sample DNN Time 0.00246\tTrain Loss 1.2803\t\n",
      "Epoch: [8][199/243]\tPer Sample Total Time 0.00250\tPer Sample Data Time 0.00004\tPer Sample DNN Time 0.00247\tTrain Loss 1.2333\t\n",
      "start validation\n",
      "validation finished\n",
      "---------------------Epoch 8 Results---------------------\n",
      "ACC: 0.856604\n",
      "mAP: 0.914238\n",
      "AUC: 0.973431\n",
      "Avg Precision: 0.295276\n",
      "Avg Recall: 0.988671\n",
      "d_prime: 2.734811\n",
      "train_loss: 1.281030\n",
      "valid_loss: 1.176229\n",
      "Epoch-8 lr: 0.0001\n",
      "epoch 8 training time: 41.255\n",
      "2022-07-16 17:50:15.693757\n",
      "Epoch: [9][56/243]\tPer Sample Total Time 0.00259\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.00246\tTrain Loss 1.2326\t\n",
      "Epoch: [9][156/243]\tPer Sample Total Time 0.00250\tPer Sample Data Time 0.00005\tPer Sample DNN Time 0.00246\tTrain Loss 1.2579\t\n",
      "start validation\n",
      "validation finished\n",
      "---------------------Epoch 9 Results---------------------\n",
      "ACC: 0.874394\n",
      "mAP: 0.907809\n",
      "AUC: 0.970574\n",
      "Avg Precision: 0.288932\n",
      "Avg Recall: 0.982749\n",
      "d_prime: 2.671874\n",
      "train_loss: 1.270847\n",
      "valid_loss: 1.165820\n",
      "Epoch-9 lr: 0.0001\n",
      "epoch 9 training time: 41.035\n",
      "2022-07-16 17:50:56.728555\n",
      "Epoch: [10][13/243]\tPer Sample Total Time 0.00300\tPer Sample Data Time 0.00051\tPer Sample DNN Time 0.00250\tTrain Loss 1.2950\t\n",
      "Epoch: [10][113/243]\tPer Sample Total Time 0.00252\tPer Sample Data Time 0.00006\tPer Sample DNN Time 0.00246\tTrain Loss 1.1880\t\n",
      "Epoch: [10][213/243]\tPer Sample Total Time 0.00249\tPer Sample Data Time 0.00004\tPer Sample DNN Time 0.00246\tTrain Loss 1.2792\t\n",
      "start validation\n",
      "validation finished\n",
      "---------------------Epoch 10 Results---------------------\n",
      "ACC: 0.866307\n",
      "mAP: 0.925667\n",
      "AUC: 0.976661\n",
      "Avg Precision: 0.293951\n",
      "Avg Recall: 0.989223\n",
      "d_prime: 2.813161\n",
      "train_loss: 1.261807\n",
      "valid_loss: 1.165694\n",
      "Epoch-10 lr: 0.0001\n",
      "epoch 10 training time: 41.098\n",
      "2022-07-16 17:51:37.826212\n",
      "Epoch: [11][70/243]\tPer Sample Total Time 0.00256\tPer Sample Data Time 0.00010\tPer Sample DNN Time 0.00246\tTrain Loss 1.2648\t\n",
      "Epoch: [11][170/243]\tPer Sample Total Time 0.00250\tPer Sample Data Time 0.00004\tPer Sample DNN Time 0.00246\tTrain Loss 1.2400\t\n",
      "start validation\n",
      "validation finished\n",
      "---------------------Epoch 11 Results---------------------\n",
      "ACC: 0.878167\n",
      "mAP: 0.916061\n",
      "AUC: 0.974356\n",
      "Avg Precision: 0.289171\n",
      "Avg Recall: 0.985444\n",
      "d_prime: 2.756401\n",
      "train_loss: 1.255550\n",
      "valid_loss: 1.158269\n",
      "Epoch-11 lr: 0.0001\n",
      "epoch 11 training time: 41.126\n",
      "2022-07-16 17:52:18.952276\n",
      "Epoch: [12][27/243]\tPer Sample Total Time 0.00275\tPer Sample Data Time 0.00027\tPer Sample DNN Time 0.00248\tTrain Loss 1.3129\t\n",
      "Epoch: [12][127/243]\tPer Sample Total Time 0.00252\tPer Sample Data Time 0.00006\tPer Sample DNN Time 0.00246\tTrain Loss 1.2188\t\n",
      "Epoch: [12][227/243]\tPer Sample Total Time 0.00249\tPer Sample Data Time 0.00004\tPer Sample DNN Time 0.00246\tTrain Loss 1.1766\t\n",
      "start validation\n",
      "validation finished\n",
      "---------------------Epoch 12 Results---------------------\n",
      "ACC: 0.864151\n",
      "mAP: 0.925258\n",
      "AUC: 0.979519\n",
      "Avg Precision: 0.291674\n",
      "Avg Recall: 0.991372\n",
      "d_prime: 2.890518\n",
      "train_loss: 1.250237\n",
      "valid_loss: 1.171060\n",
      "Epoch-12 lr: 0.0001\n",
      "epoch 12 training time: 41.108\n",
      "2022-07-16 17:53:00.060749\n",
      "Epoch: [13][84/243]\tPer Sample Total Time 0.00256\tPer Sample Data Time 0.00010\tPer Sample DNN Time 0.00246\tTrain Loss 1.2488\t\n",
      "Epoch: [13][184/243]\tPer Sample Total Time 0.00252\tPer Sample Data Time 0.00005\tPer Sample DNN Time 0.00248\tTrain Loss 1.2145\t\n",
      "start validation\n",
      "validation finished\n",
      "---------------------Epoch 13 Results---------------------\n",
      "ACC: 0.884636\n",
      "mAP: 0.913875\n",
      "AUC: 0.973542\n",
      "Avg Precision: 0.288305\n",
      "Avg Recall: 0.985444\n",
      "d_prime: 2.737353\n",
      "train_loss: 1.244380\n",
      "valid_loss: 1.158644\n",
      "Epoch-13 lr: 0.0001\n",
      "epoch 13 training time: 41.432\n",
      "2022-07-16 17:53:41.493080\n",
      "Epoch: [14][41/243]\tPer Sample Total Time 0.00265\tPer Sample Data Time 0.00017\tPer Sample DNN Time 0.00247\tTrain Loss 1.1754\t\n",
      "Epoch: [14][141/243]\tPer Sample Total Time 0.00251\tPer Sample Data Time 0.00005\tPer Sample DNN Time 0.00246\tTrain Loss 1.2069\t\n",
      "Epoch: [14][241/243]\tPer Sample Total Time 0.00249\tPer Sample Data Time 0.00003\tPer Sample DNN Time 0.00246\tTrain Loss 1.3315\t\n",
      "start validation\n",
      "validation finished\n",
      "---------------------Epoch 14 Results---------------------\n",
      "ACC: 0.873315\n",
      "mAP: 0.914417\n",
      "AUC: 0.975509\n",
      "Avg Precision: 0.290167\n",
      "Avg Recall: 0.987053\n",
      "d_prime: 2.784219\n",
      "train_loss: 1.239661\n",
      "valid_loss: 1.166809\n",
      "Epoch-14 lr: 0.0001\n",
      "epoch 14 training time: 41.119\n",
      "2022-07-16 17:54:22.612546\n",
      "Epoch: [15][98/243]\tPer Sample Total Time 0.00254\tPer Sample Data Time 0.00008\tPer Sample DNN Time 0.00246\tTrain Loss 1.2308\t\n",
      "Epoch: [15][198/243]\tPer Sample Total Time 0.00250\tPer Sample Data Time 0.00004\tPer Sample DNN Time 0.00245\tTrain Loss 1.2774\t\n",
      "start validation\n",
      "validation finished\n",
      "---------------------Epoch 15 Results---------------------\n",
      "ACC: 0.880323\n",
      "mAP: 0.923556\n",
      "AUC: 0.979692\n",
      "Avg Precision: 0.290102\n",
      "Avg Recall: 0.989768\n",
      "d_prime: 2.895500\n",
      "train_loss: 1.239912\n",
      "valid_loss: 1.152366\n",
      "Epoch-15 lr: 0.0001\n",
      "epoch 15 training time: 41.269\n",
      "2022-07-16 17:55:03.881860\n",
      "Epoch: [16][55/243]\tPer Sample Total Time 0.00270\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.00255\tTrain Loss 1.2500\t\n",
      "Epoch: [16][155/243]\tPer Sample Total Time 0.00263\tPer Sample Data Time 0.00005\tPer Sample DNN Time 0.00257\tTrain Loss 1.1893\t\n",
      "start validation\n",
      "validation finished\n",
      "---------------------Epoch 16 Results---------------------\n",
      "ACC: 0.878167\n",
      "mAP: 0.920236\n",
      "AUC: 0.977321\n",
      "Avg Precision: 0.289351\n",
      "Avg Recall: 0.986516\n",
      "d_prime: 2.830293\n",
      "train_loss: 1.227066\n",
      "valid_loss: 1.156829\n",
      "Epoch-16 lr: 0.0001\n",
      "epoch 16 training time: 42.805\n",
      "2022-07-16 17:55:46.686747\n",
      "Epoch: [17][12/243]\tPer Sample Total Time 0.00302\tPer Sample Data Time 0.00054\tPer Sample DNN Time 0.00248\tTrain Loss 1.1917\t\n",
      "Epoch: [17][112/243]\tPer Sample Total Time 0.00252\tPer Sample Data Time 0.00006\tPer Sample DNN Time 0.00246\tTrain Loss 1.1819\t\n",
      "Epoch: [17][212/243]\tPer Sample Total Time 0.00251\tPer Sample Data Time 0.00003\tPer Sample DNN Time 0.00248\tTrain Loss 1.2471\t\n",
      "start validation\n",
      "validation finished\n",
      "---------------------Epoch 17 Results---------------------\n",
      "ACC: 0.887332\n",
      "mAP: 0.931326\n",
      "AUC: 0.981072\n",
      "Avg Precision: 0.289702\n",
      "Avg Recall: 0.990829\n",
      "d_prime: 2.936503\n",
      "train_loss: 1.229011\n",
      "valid_loss: 1.146568\n",
      "Epoch-17 lr: 0.0001\n",
      "epoch 17 training time: 41.449\n",
      "2022-07-16 17:56:28.135899\n",
      "Epoch: [18][69/243]\tPer Sample Total Time 0.00257\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.00246\tTrain Loss 1.1686\t\n",
      "Epoch: [18][169/243]\tPer Sample Total Time 0.00250\tPer Sample Data Time 0.00005\tPer Sample DNN Time 0.00245\tTrain Loss 1.2938\t\n",
      "start validation\n",
      "validation finished\n",
      "---------------------Epoch 18 Results---------------------\n",
      "ACC: 0.894879\n",
      "mAP: 0.932608\n",
      "AUC: 0.978995\n",
      "Avg Precision: 0.289689\n",
      "Avg Recall: 0.988137\n",
      "d_prime: 2.875704\n",
      "train_loss: 1.228300\n",
      "valid_loss: 1.144385\n",
      "Epoch-18 lr: 0.0001\n",
      "epoch 18 training time: 41.151\n",
      "2022-07-16 17:57:09.287398\n",
      "Epoch: [19][26/243]\tPer Sample Total Time 0.00278\tPer Sample Data Time 0.00029\tPer Sample DNN Time 0.00249\tTrain Loss 1.2097\t\n",
      "Epoch: [19][126/243]\tPer Sample Total Time 0.00252\tPer Sample Data Time 0.00006\tPer Sample DNN Time 0.00246\tTrain Loss 1.3147\t\n",
      "Epoch: [19][226/243]\tPer Sample Total Time 0.00249\tPer Sample Data Time 0.00004\tPer Sample DNN Time 0.00246\tTrain Loss 1.1960\t\n",
      "start validation\n",
      "validation finished\n",
      "---------------------Epoch 19 Results---------------------\n",
      "ACC: 0.893261\n",
      "mAP: 0.926933\n",
      "AUC: 0.980895\n",
      "Avg Precision: 0.289435\n",
      "Avg Recall: 0.992456\n",
      "d_prime: 2.931090\n",
      "train_loss: 1.222035\n",
      "valid_loss: 1.142962\n",
      "Epoch-19 lr: 0.0001\n",
      "epoch 19 training time: 41.166\n",
      "2022-07-16 17:57:50.453662\n",
      "Epoch: [20][83/243]\tPer Sample Total Time 0.00255\tPer Sample Data Time 0.00010\tPer Sample DNN Time 0.00246\tTrain Loss 1.2008\t\n",
      "Epoch: [20][183/243]\tPer Sample Total Time 0.00250\tPer Sample Data Time 0.00005\tPer Sample DNN Time 0.00246\tTrain Loss 1.1780\t\n",
      "start validation\n",
      "validation finished\n",
      "---------------------Epoch 20 Results---------------------\n",
      "ACC: 0.885714\n",
      "mAP: 0.929584\n",
      "AUC: 0.980759\n",
      "Avg Precision: 0.289515\n",
      "Avg Recall: 0.990831\n",
      "d_prime: 2.926984\n",
      "train_loss: 1.222363\n",
      "valid_loss: 1.149585\n",
      "Epoch-20 lr: 0.0001\n",
      "epoch 20 training time: 41.147\n",
      "2022-07-16 17:58:31.600336\n",
      "Epoch: [21][40/243]\tPer Sample Total Time 0.00266\tPer Sample Data Time 0.00020\tPer Sample DNN Time 0.00246\tTrain Loss 1.1917\t\n",
      "Epoch: [21][140/243]\tPer Sample Total Time 0.00252\tPer Sample Data Time 0.00006\tPer Sample DNN Time 0.00246\tTrain Loss 1.2676\t\n",
      "Epoch: [21][240/243]\tPer Sample Total Time 0.00249\tPer Sample Data Time 0.00004\tPer Sample DNN Time 0.00246\tTrain Loss 1.1828\t\n",
      "start validation\n",
      "validation finished\n",
      "---------------------Epoch 21 Results---------------------\n",
      "ACC: 0.892722\n",
      "mAP: 0.926565\n",
      "AUC: 0.979055\n",
      "Avg Precision: 0.289394\n",
      "Avg Recall: 0.988677\n",
      "d_prime: 2.877383\n",
      "train_loss: 1.219529\n",
      "valid_loss: 1.146541\n",
      "Epoch-21 lr: 0.0001\n",
      "epoch 21 training time: 41.145\n",
      "2022-07-16 17:59:12.745373\n",
      "Epoch: [22][97/243]\tPer Sample Total Time 0.00254\tPer Sample Data Time 0.00008\tPer Sample DNN Time 0.00246\tTrain Loss 1.2511\t\n",
      "Epoch: [22][197/243]\tPer Sample Total Time 0.00250\tPer Sample Data Time 0.00004\tPer Sample DNN Time 0.00246\tTrain Loss 1.1917\t\n",
      "start validation\n",
      "validation finished\n",
      "---------------------Epoch 22 Results---------------------\n",
      "ACC: 0.878706\n",
      "mAP: 0.925443\n",
      "AUC: 0.979261\n",
      "Avg Precision: 0.290584\n",
      "Avg Recall: 0.989755\n",
      "d_prime: 2.883185\n",
      "train_loss: 1.216502\n",
      "valid_loss: 1.153985\n",
      "Epoch-22 lr: 0.0001\n",
      "epoch 22 training time: 41.122\n",
      "2022-07-16 17:59:53.867238\n",
      "Epoch: [23][54/243]\tPer Sample Total Time 0.00260\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.00246\tTrain Loss 1.2032\t\n",
      "Epoch: [23][154/243]\tPer Sample Total Time 0.00251\tPer Sample Data Time 0.00005\tPer Sample DNN Time 0.00245\tTrain Loss 1.1706\t\n",
      "start validation\n",
      "validation finished\n",
      "---------------------Epoch 23 Results---------------------\n",
      "ACC: 0.894340\n",
      "mAP: 0.933414\n",
      "AUC: 0.982536\n",
      "Avg Precision: 0.289854\n",
      "Avg Recall: 0.992450\n",
      "d_prime: 2.982844\n",
      "train_loss: 1.210668\n",
      "valid_loss: 1.141275\n",
      "Epoch-23 lr: 0.0001\n",
      "epoch 23 training time: 41.129\n",
      "2022-07-16 18:00:34.996642\n",
      "Epoch: [24][11/243]\tPer Sample Total Time 0.00315\tPer Sample Data Time 0.00064\tPer Sample DNN Time 0.00251\tTrain Loss 1.1828\t\n",
      "Epoch: [24][111/243]\tPer Sample Total Time 0.00253\tPer Sample Data Time 0.00007\tPer Sample DNN Time 0.00246\tTrain Loss 1.2200\t\n",
      "Epoch: [24][211/243]\tPer Sample Total Time 0.00249\tPer Sample Data Time 0.00004\tPer Sample DNN Time 0.00246\tTrain Loss 1.2694\t\n",
      "start validation\n",
      "validation finished\n",
      "---------------------Epoch 24 Results---------------------\n",
      "ACC: 0.898652\n",
      "mAP: 0.930017\n",
      "AUC: 0.980372\n",
      "Avg Precision: 0.289325\n",
      "Avg Recall: 0.988682\n",
      "d_prime: 2.915403\n",
      "train_loss: 1.211500\n",
      "valid_loss: 1.144049\n",
      "Epoch-24 lr: 0.0001\n",
      "epoch 24 training time: 41.132\n",
      "2022-07-16 18:01:16.128649\n",
      "Epoch: [25][68/243]\tPer Sample Total Time 0.00257\tPer Sample Data Time 0.00010\tPer Sample DNN Time 0.00247\tTrain Loss 1.2303\t\n",
      "Epoch: [25][168/243]\tPer Sample Total Time 0.00252\tPer Sample Data Time 0.00004\tPer Sample DNN Time 0.00247\tTrain Loss 1.3016\t\n",
      "start validation\n",
      "validation finished\n",
      "---------------------Epoch 25 Results---------------------\n",
      "ACC: 0.896496\n",
      "mAP: 0.934016\n",
      "AUC: 0.982112\n",
      "Avg Precision: 0.289595\n",
      "Avg Recall: 0.991913\n",
      "d_prime: 2.969103\n",
      "train_loss: 1.210540\n",
      "valid_loss: 1.137597\n",
      "Epoch-25 lr: 0.0001\n",
      "epoch 25 training time: 41.189\n",
      "2022-07-16 18:01:57.317982\n",
      "Epoch: [26][25/243]\tPer Sample Total Time 0.00275\tPer Sample Data Time 0.00027\tPer Sample DNN Time 0.00248\tTrain Loss 1.2257\t\n",
      "Epoch: [26][125/243]\tPer Sample Total Time 0.00251\tPer Sample Data Time 0.00006\tPer Sample DNN Time 0.00245\tTrain Loss 1.2362\t\n",
      "Epoch: [26][225/243]\tPer Sample Total Time 0.00249\tPer Sample Data Time 0.00003\tPer Sample DNN Time 0.00246\tTrain Loss 1.1621\t\n",
      "start validation\n",
      "validation finished\n",
      "---------------------Epoch 26 Results---------------------\n",
      "ACC: 0.897035\n",
      "mAP: 0.938928\n",
      "AUC: 0.983009\n",
      "Avg Precision: 0.290036\n",
      "Avg Recall: 0.992449\n",
      "d_prime: 2.998521\n",
      "train_loss: 1.209070\n",
      "valid_loss: 1.138994\n",
      "Epoch-26 lr: 0.0001\n",
      "epoch 26 training time: 41.095\n",
      "2022-07-16 18:02:38.412663\n",
      "Epoch: [27][82/243]\tPer Sample Total Time 0.00259\tPer Sample Data Time 0.00008\tPer Sample DNN Time 0.00250\tTrain Loss 1.2272\t\n",
      "Epoch: [27][182/243]\tPer Sample Total Time 0.00251\tPer Sample Data Time 0.00004\tPer Sample DNN Time 0.00247\tTrain Loss 1.2100\t\n",
      "start validation\n",
      "validation finished\n",
      "---------------------Epoch 27 Results---------------------\n",
      "ACC: 0.899730\n",
      "mAP: 0.937271\n",
      "AUC: 0.982639\n",
      "Avg Precision: 0.291854\n",
      "Avg Recall: 0.990832\n",
      "d_prime: 2.986231\n",
      "train_loss: 1.206604\n",
      "valid_loss: 1.138856\n",
      "Epoch-27 lr: 0.0001\n",
      "epoch 27 training time: 41.297\n",
      "2022-07-16 18:03:19.709932\n",
      "Epoch: [28][39/243]\tPer Sample Total Time 0.00267\tPer Sample Data Time 0.00017\tPer Sample DNN Time 0.00249\tTrain Loss 1.2661\t\n",
      "Epoch: [28][139/243]\tPer Sample Total Time 0.00259\tPer Sample Data Time 0.00005\tPer Sample DNN Time 0.00254\tTrain Loss 1.1933\t\n",
      "Epoch: [28][239/243]\tPer Sample Total Time 0.00259\tPer Sample Data Time 0.00003\tPer Sample DNN Time 0.00256\tTrain Loss 1.2592\t\n",
      "start validation\n",
      "validation finished\n",
      "---------------------Epoch 28 Results---------------------\n",
      "ACC: 0.888949\n",
      "mAP: 0.931616\n",
      "AUC: 0.981032\n",
      "Avg Precision: 0.291155\n",
      "Avg Recall: 0.992988\n",
      "d_prime: 2.935267\n",
      "train_loss: 1.207392\n",
      "valid_loss: 1.143391\n",
      "Epoch-28 lr: 0.0001\n",
      "epoch 28 training time: 42.787\n",
      "2022-07-16 18:04:02.496911\n",
      "Epoch: [29][96/243]\tPer Sample Total Time 0.00266\tPer Sample Data Time 0.00009\tPer Sample DNN Time 0.00257\tTrain Loss 1.1824\t\n",
      "Epoch: [29][196/243]\tPer Sample Total Time 0.00257\tPer Sample Data Time 0.00005\tPer Sample DNN Time 0.00252\tTrain Loss 1.2016\t\n",
      "start validation\n",
      "validation finished\n",
      "---------------------Epoch 29 Results---------------------\n",
      "ACC: 0.898113\n",
      "mAP: 0.942045\n",
      "AUC: 0.984840\n",
      "Avg Precision: 0.290175\n",
      "Avg Recall: 0.993531\n",
      "d_prime: 3.063013\n",
      "train_loss: 1.202615\n",
      "valid_loss: 1.139872\n",
      "Epoch-29 lr: 0.0001\n",
      "epoch 29 training time: 42.120\n",
      "2022-07-16 18:04:44.616563\n",
      "Epoch: [30][53/243]\tPer Sample Total Time 0.00265\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.00252\tTrain Loss 1.1885\t\n",
      "Epoch: [30][153/243]\tPer Sample Total Time 0.00261\tPer Sample Data Time 0.00005\tPer Sample DNN Time 0.00256\tTrain Loss 1.1834\t\n",
      "start validation\n",
      "validation finished\n",
      "---------------------Epoch 30 Results---------------------\n",
      "ACC: 0.887332\n",
      "mAP: 0.932415\n",
      "AUC: 0.982320\n",
      "Avg Precision: 0.290702\n",
      "Avg Recall: 0.994067\n",
      "d_prime: 2.975796\n",
      "train_loss: 1.207601\n",
      "valid_loss: 1.147246\n",
      "Epoch-30 lr: 0.0001\n",
      "epoch 30 training time: 42.715\n"
     ]
    }
   ],
   "source": [
    "print('Now starting training for {:d} epochs'.format(n_epochs))\n",
    "train(audio_model, train_loader, val_loader, exp_dir,lr,weight_decay,n_epochs,n_print_steps,save_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4784d782-d8da-401f-bb65-bcf569a9315f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test on the test set and sub-test set, model selected on the validation set\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "sd = torch.load(exp_dir + '/models/best_audio_model.pth', map_location=device)\n",
    "audio_model = torch.nn.DataParallel(audio_model)\n",
    "audio_model.load_state_dict(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88524373-e7a0-46a8-b9bc-266968498ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_res = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81c1f23a-b676-46e8-bb79-2c71762e4823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------evaluate on the validation set---------------\n",
      "Accuracy: 0.899730\n"
     ]
    }
   ],
   "source": [
    "# best model on the validation set, repeat to confirm\n",
    "stats, _ = validate(audio_model, val_loader, exp_dir, 'valid_set')\n",
    "# note it is NOT mean of class-wise accuracy\n",
    "val_acc = stats[0]['acc']\n",
    "val_mAUC = np.mean([stat['auc'] for stat in stats])\n",
    "print('---------------evaluate on the validation set---------------')\n",
    "print(\"Accuracy: {:.6f}\".format(val_acc))\n",
    "all_res.append(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f96d5ae-f053-41de-b6d8-d6887835db11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model on the evaluation set\n",
    "data_eval_list = ['te.json', 'subtest/te_age1.json', 'subtest/te_age2.json', 'subtest/te_age3.json', 'subtest/te_female.json', 'subtest/te_male.json']\n",
    "eval_name_list = ['all_test', 'test age 18-25', 'test age 26-48', 'test age 49-80', 'test female', 'test male']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "924eccea-e7e0-41e2-93a8-710cc0ade004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------evaluate on all_test---------------\n",
      "Accuracy: 0.909217\n",
      "---------------evaluate on test age 18-25---------------\n",
      "Accuracy: 0.920404\n",
      "---------------evaluate on test age 26-48---------------\n",
      "Accuracy: 0.904296\n",
      "---------------evaluate on test age 49-80---------------\n",
      "Accuracy: 0.913793\n",
      "---------------evaluate on test female---------------\n",
      "Accuracy: 0.917840\n",
      "---------------evaluate on test male---------------\n",
      "Accuracy: 0.901017\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/'.join(data_val.split('/')[:-1])\n",
    "for idx, cur_eval in enumerate(data_eval_list):\n",
    "    cur_eval = data_dir + '/' + cur_eval\n",
    "    eval_loader = torch.utils.data.DataLoader(\n",
    "        dataloaders.VSDataset(cur_eval, label_csv=label_csv, audio_conf=val_audio_conf),\n",
    "        batch_size=batch_size*2, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "    stats, _ = validate(audio_model, eval_loader, exp_dir, eval_name_list[idx])\n",
    "    eval_acc = stats[0]['acc']\n",
    "    all_res.append(eval_acc)\n",
    "    print('---------------evaluate on {:s}---------------'.format(eval_name_list[idx]))\n",
    "    print(\"Accuracy: {:.6f}\".format(eval_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "665ac0a6-bb30-43c8-85b3-0793d6905831",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_res = np.array(all_res)\n",
    "all_res = all_res.reshape([1, all_res.shape[0]])\n",
    "np.savetxt(exp_dir + '/all_eval_result.csv', all_res, header=','.join(['validation'] + eval_name_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a28ba0-9acb-40bb-8681-f14b7b489b7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d5c872-511c-4f7a-b743-dd9ee86fe2bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a8d479-5a73-4b62-a470-95a748757a21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137ca8ef-3370-4d8a-a9be-382f9ade93ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vs",
   "language": "python",
   "name": "vs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
